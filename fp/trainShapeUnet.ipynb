{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runs a shape regularization CNN training based on UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skimage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2987fe872b17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'skimage'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "np.random.seed(0)  # for reproducibility\n",
    "\n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import EarlyStopping  \n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape regularization model (the model is U-Net without concatenation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-060ebed9204a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-060ebed9204a>\u001b[0m in \u001b[0;36munet\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0munet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'he_normal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'he_normal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Input' is not defined"
     ]
    }
   ],
   "source": [
    "def unet():\n",
    "    n = 64\n",
    "    inputs = Input((n,n,1))\n",
    "    conv1 = Conv2D(n//4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(n//4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(n//2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(n//2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(n, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(n, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(2*n, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(2*n, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(4*n, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(4*n, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(2*n, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(2*n, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(2*n, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(n, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    conv7 = Conv2D(n, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(up7)\n",
    "    conv7 = Conv2D(n, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(n//2, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    conv8 = Conv2D(n//2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(up8)\n",
    "    conv8 = Conv2D(n//2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(n//4, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    conv9 = Conv2D(n//4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(up9)\n",
    "    conv9 = Conv2D(n//4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = Model(input = inputs, output = conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['mae'])\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "model = unet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train data load and data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14954, 64, 64, 1)\n",
      "(14954, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.load(\"X_train.npy\")\n",
    "Y_train = np.load(\"Y_train.npy\")\n",
    "Y_train = Y_train.reshape(Y_train.shape[0],64,64,1)\n",
    "print (X_train.shape)\n",
    "print (Y_train.shape)\n",
    "\n",
    "data_gen_args_image = dict(featurewise_center=True,\n",
    "                 featurewise_std_normalization=True,\n",
    "                 rotation_range=60.,\n",
    "                 width_shift_range=0.1,\n",
    "                 height_shift_range=0.1,\n",
    "                 zoom_range=0)\n",
    "    \n",
    "data_gen_args_mask = dict(featurewise_center=False,\n",
    "                 featurewise_std_normalization=False,\n",
    "                 rotation_range=60.,\n",
    "                 width_shift_range=0.1,\n",
    "                 height_shift_range=0.1,\n",
    "                 zoom_range=0)\n",
    "image_datagen = ImageDataGenerator(**data_gen_args_image)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args_mask)\n",
    "\n",
    "# Provide the same seed and keyword arguments to the fit and flow methods\n",
    "seed = 1\n",
    "image_datagen.fit(X_train, augment=True, seed=seed)\n",
    "mask_datagen.fit(Y_train, augment=True, seed=seed)\n",
    "image_generator = image_datagen.flow(X_train,seed=seed)\n",
    "mask_generator = mask_datagen.flow(Y_train,seed=seed)\n",
    "train_generator = zip(image_generator, mask_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define keras callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "early_stop = EarlyStopping(monitor='mean_absolute_error', min_delta=0.001, patience=5, mode='min', verbose=1)\n",
    "checkpoint = ModelCheckpoint(\"weights.{epoch:02d}.hdf5\", monitor='mean_absolute_error', verbose=1, save_best_only=False, mode='min', period=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2000/2000 [==============================] - 968s 484ms/step - loss: 0.2802 - mean_absolute_error: 0.1892\n",
      "\n",
      "Epoch 00001: saving model to weights.01.hdf5\n",
      "Epoch 2/100\n",
      "2000/2000 [==============================] - 971s 485ms/step - loss: 0.2214 - mean_absolute_error: 0.1528\n",
      "\n",
      "Epoch 00002: saving model to weights.02.hdf5\n",
      "Epoch 3/100\n",
      "2000/2000 [==============================] - 978s 489ms/step - loss: 0.1900 - mean_absolute_error: 0.1332\n",
      "\n",
      "Epoch 00003: saving model to weights.03.hdf5\n",
      "Epoch 4/100\n",
      "2000/2000 [==============================] - 967s 484ms/step - loss: 0.1667 - mean_absolute_error: 0.1181\n",
      "\n",
      "Epoch 00004: saving model to weights.04.hdf5\n",
      "Epoch 5/100\n",
      "2000/2000 [==============================] - 978s 489ms/step - loss: 0.1466 - mean_absolute_error: 0.1046\n",
      "\n",
      "Epoch 00005: saving model to weights.05.hdf5\n",
      "Epoch 6/100\n",
      "2000/2000 [==============================] - 951s 475ms/step - loss: 0.1312 - mean_absolute_error: 0.0935\n",
      "\n",
      "Epoch 00006: saving model to weights.06.hdf5\n",
      "Epoch 7/100\n",
      "2000/2000 [==============================] - 964s 482ms/step - loss: 0.1167 - mean_absolute_error: 0.0829\n",
      "\n",
      "Epoch 00007: saving model to weights.07.hdf5\n",
      "Epoch 8/100\n",
      "2000/2000 [==============================] - 964s 482ms/step - loss: 0.1048 - mean_absolute_error: 0.0739\n",
      "\n",
      "Epoch 00008: saving model to weights.08.hdf5\n",
      "Epoch 9/100\n",
      "2000/2000 [==============================] - 954s 477ms/step - loss: 0.0951 - mean_absolute_error: 0.0661\n",
      "\n",
      "Epoch 00009: saving model to weights.09.hdf5\n",
      "Epoch 10/100\n",
      "2000/2000 [==============================] - 965s 483ms/step - loss: 0.0865 - mean_absolute_error: 0.0591\n",
      "\n",
      "Epoch 00010: saving model to weights.10.hdf5\n",
      "Epoch 11/100\n",
      "2000/2000 [==============================] - 952s 476ms/step - loss: 0.0784 - mean_absolute_error: 0.0527\n",
      "\n",
      "Epoch 00011: saving model to weights.11.hdf5\n",
      "Epoch 12/100\n",
      "2000/2000 [==============================] - 956s 478ms/step - loss: 0.0733 - mean_absolute_error: 0.0480\n",
      "\n",
      "Epoch 00012: saving model to weights.12.hdf5\n",
      "Epoch 13/100\n",
      "2000/2000 [==============================] - 956s 478ms/step - loss: 0.0679 - mean_absolute_error: 0.0434\n",
      "\n",
      "Epoch 00013: saving model to weights.13.hdf5\n",
      "Epoch 14/100\n",
      "2000/2000 [==============================] - 976s 488ms/step - loss: 0.0623 - mean_absolute_error: 0.0389\n",
      "\n",
      "Epoch 00014: saving model to weights.14.hdf5\n",
      "Epoch 15/100\n",
      "2000/2000 [==============================] - 971s 485ms/step - loss: 0.0584 - mean_absolute_error: 0.0355\n",
      "\n",
      "Epoch 00015: saving model to weights.15.hdf5\n",
      "Epoch 16/100\n",
      "2000/2000 [==============================] - 979s 490ms/step - loss: 0.0554 - mean_absolute_error: 0.0328\n",
      "\n",
      "Epoch 00016: saving model to weights.16.hdf5\n",
      "Epoch 17/100\n",
      "2000/2000 [==============================] - 966s 483ms/step - loss: 0.0525 - mean_absolute_error: 0.0303\n",
      "\n",
      "Epoch 00017: saving model to weights.17.hdf5\n",
      "Epoch 18/100\n",
      "2000/2000 [==============================] - 976s 488ms/step - loss: 0.0496 - mean_absolute_error: 0.0278\n",
      "\n",
      "Epoch 00018: saving model to weights.18.hdf5\n",
      "Epoch 19/100\n",
      "2000/2000 [==============================] - 958s 479ms/step - loss: 0.0470 - mean_absolute_error: 0.0257\n",
      "\n",
      "Epoch 00019: saving model to weights.19.hdf5\n",
      "Epoch 20/100\n",
      "2000/2000 [==============================] - 962s 481ms/step - loss: 0.0459 - mean_absolute_error: 0.0245\n",
      "\n",
      "Epoch 00020: saving model to weights.20.hdf5\n",
      "Epoch 21/100\n",
      "2000/2000 [==============================] - 973s 487ms/step - loss: 0.0438 - mean_absolute_error: 0.0229\n",
      "\n",
      "Epoch 00021: saving model to weights.21.hdf5\n",
      "Epoch 22/100\n",
      "2000/2000 [==============================] - 966s 483ms/step - loss: 0.0424 - mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00022: saving model to weights.22.hdf5\n",
      "Epoch 23/100\n",
      "2000/2000 [==============================] - 954s 477ms/step - loss: 0.0414 - mean_absolute_error: 0.0208\n",
      "\n",
      "Epoch 00023: saving model to weights.23.hdf5\n",
      "Epoch 24/100\n",
      "2000/2000 [==============================] - 953s 476ms/step - loss: 0.0407 - mean_absolute_error: 0.0201\n",
      "\n",
      "Epoch 00024: saving model to weights.24.hdf5\n",
      "Epoch 25/100\n",
      "2000/2000 [==============================] - 974s 487ms/step - loss: 0.0387 - mean_absolute_error: 0.0188\n",
      "\n",
      "Epoch 00025: saving model to weights.25.hdf5\n",
      "Epoch 26/100\n",
      "2000/2000 [==============================] - 960s 480ms/step - loss: 0.0380 - mean_absolute_error: 0.0182\n",
      "\n",
      "Epoch 00026: saving model to weights.26.hdf5\n",
      "Epoch 27/100\n",
      "2000/2000 [==============================] - 968s 484ms/step - loss: 0.0384 - mean_absolute_error: 0.0182\n",
      "\n",
      "Epoch 00027: saving model to weights.27.hdf5\n",
      "Epoch 28/100\n",
      "2000/2000 [==============================] - 988s 494ms/step - loss: 0.0363 - mean_absolute_error: 0.0170\n",
      "\n",
      "Epoch 00028: saving model to weights.28.hdf5\n",
      "Epoch 29/100\n",
      "2000/2000 [==============================] - 969s 484ms/step - loss: 0.0361 - mean_absolute_error: 0.0167\n",
      "\n",
      "Epoch 00029: saving model to weights.29.hdf5\n",
      "Epoch 30/100\n",
      "2000/2000 [==============================] - 960s 480ms/step - loss: 0.0354 - mean_absolute_error: 0.0162\n",
      "\n",
      "Epoch 00030: saving model to weights.30.hdf5\n",
      "Epoch 31/100\n",
      "2000/2000 [==============================] - 968s 484ms/step - loss: 0.0349 - mean_absolute_error: 0.0158\n",
      "\n",
      "Epoch 00031: saving model to weights.31.hdf5\n",
      "Epoch 32/100\n",
      "2000/2000 [==============================] - 956s 478ms/step - loss: 0.0362 - mean_absolute_error: 0.0164\n",
      "\n",
      "Epoch 00032: saving model to weights.32.hdf5\n",
      "Epoch 33/100\n",
      "2000/2000 [==============================] - 973s 487ms/step - loss: 0.0339 - mean_absolute_error: 0.0151\n",
      "\n",
      "Epoch 00033: saving model to weights.33.hdf5\n",
      "Epoch 34/100\n",
      "2000/2000 [==============================] - 967s 483ms/step - loss: 0.0337 - mean_absolute_error: 0.0150\n",
      "\n",
      "Epoch 00034: saving model to weights.34.hdf5\n",
      "Epoch 35/100\n",
      "2000/2000 [==============================] - 974s 487ms/step - loss: 0.0347 - mean_absolute_error: 0.0154\n",
      "\n",
      "Epoch 00035: saving model to weights.35.hdf5\n",
      "Epoch 36/100\n",
      "2000/2000 [==============================] - 971s 485ms/step - loss: 0.0329 - mean_absolute_error: 0.0144\n",
      "\n",
      "Epoch 00036: saving model to weights.36.hdf5\n",
      "Epoch 37/100\n",
      "2000/2000 [==============================] - 966s 483ms/step - loss: 0.0327 - mean_absolute_error: 0.0143\n",
      "\n",
      "Epoch 00037: saving model to weights.37.hdf5\n",
      "Epoch 38/100\n",
      "2000/2000 [==============================] - 960s 480ms/step - loss: 0.0324 - mean_absolute_error: 0.0141\n",
      "\n",
      "Epoch 00038: saving model to weights.38.hdf5\n",
      "Epoch 39/100\n",
      "2000/2000 [==============================] - 971s 486ms/step - loss: 0.0329 - mean_absolute_error: 0.0143\n",
      "\n",
      "Epoch 00039: saving model to weights.39.hdf5\n",
      "Epoch 40/100\n",
      "2000/2000 [==============================] - 983s 491ms/step - loss: 0.0319 - mean_absolute_error: 0.0137\n",
      "\n",
      "Epoch 00040: saving model to weights.40.hdf5\n",
      "Epoch 41/100\n",
      "2000/2000 [==============================] - 984s 492ms/step - loss: 0.0328 - mean_absolute_error: 0.0142\n",
      "\n",
      "Epoch 00041: saving model to weights.41.hdf5\n",
      "Epoch 00041: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_generator,steps_per_epoch=2000,epochs=100,callbacks = [early_stop,checkpoint])\n",
    "model.save('seg_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
